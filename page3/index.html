<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      sdorsett.github.io &middot; Things I find interesting
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p></p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item active" href="/">Home</a>

    

    
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/about/">About</a>
        
      
    
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/posts/">All Posts</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
    <a class="sidebar-nav-item" href="https://github.com/sdorsett/archive/v1.0.0.zip">Download</a>
    <a class="sidebar-nav-item" href="https://github.com/sdorsett">GitHub project</a>
    <span class="sidebar-nav-item">Currently v1.0.0</span>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2018. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">sdorsett.github.io</a>
            <small>Things I find interesting</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2015/12/24/installing-packer-and-ovftool-on-centos/">
        Setting up Packer, ovftool and Apache web server on a CentOS virtual machine
      </a>
    </h1>

    <span class="post-date">24 Dec 2015</span>

    <p>This is the third in a series of posts on <a href="https://sdorsett.github.io/2015/12/22/pipeline-for-creating-packer-box-files/">using a Packer pipeline to generate Vagrant .box files</a>.</p>

<p>In the <a href="https://sdorsett.github.io/2015/12/23/installing-esxi-virtual-machine-for-packer-depolyment/">last post</a> we setup a ESXi virtual machine that would be the target for creating Packer images. In order to follow along with this post you will need two things:</p>

<ul>
<li>A fresh CentOS virtual machine on which we will install Packer - I&#39;m using CentOS 6.6 minimal install named &quot;packer-centos&quot; with 2 vCPU, 4GB of memory and a 100GB virtual hard drive. I also gave this virtual machine the IP address of 192.168.1.52</li>
<li><a href="https://my.vmware.com/web/vmware/details?productId=491&downloadGroup=OVFTOOL410">VMware ovftool</a> - if you followed the previous post and are using ESXi 6.0 you will need a copy of ovftool 4.1.</li>
</ul>

<p>Let&#39;s get started...</p>

<h2>1. SSH to CentOS virtual machine you created.</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">sdorsett-mbp:~ sdorsett$ ssh root@192.168.1.52
The authenticity of host &#39;192.168.1.52 (192.168.1.52)&#39; cant be established.
RSA key fingerprint is 58:f5:22:2e:f6:64:04:59:6b:0b:76:2f:33:6f:03:85.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added &#39;192.168.1.52&#39; (RSA) to the list of known hosts.
root@192.168.1.52&#39;s password:
Last login: Thu Oct 22 17:52:17 2015 from 192.168.1.1
[root@packer-centos ~]#</code></pre></figure>

<h2>2. Install the EPEL repository</h2>

<p>There will be several package we need to install that are coming from the CentOS EPEL repository, so we will need to install it.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# yum install -y epel-release
Loaded plugins: fastestmirror
Setting up Install Process
Determining fastest mirrors
 * base: yum.tamu.edu
 * extras: centos.firehosted.com
 * updates: mirrors.adams.net
base
base/primary_db
extras
extras/primary_db
updates
updates/primary_db
Resolving Dependencies
--&gt; Running transaction check
---&gt; Package epel-release.noarch 0:6-8 will be installed
--&gt; Finished Dependency Resolution

Dependencies Resolved

=============================================================
 Package          Arch       Version     Repository     Size
=============================================================
Installing:
 epel-release     noarch     6-8         extras         14 k

Transaction Summary
=============================================================
Install       1 Package(s)

Total download size: 14 k
Installed size: 22 k
Downloading Packages:
epel-release-6-8.noarch.rpm     |  14 kB     00:00
Running rpm_check_debug
Running Transaction Test
Transaction Test Succeeded
Running Transaction
  Installing : epel-release-6-8.noarch     1/1
  Verifying  : epel-release-6-8.noarch     1/1

Installed:
  epel-release.noarch 0:6-8

Complete!

[root@packer-centos ~]#</code></pre></figure>

<h2>3. Use yum to make sure the following packages are installed:</h2>

<ul>
<li>git - for version control and the ability to pull down git repositories</li>
<li>wget - provides the ability to download packages from URLs</li>
<li>unzip - needed to unzip Packer, since it comes as a .zip</li>
<li>sshpass - used for running SSH commands, but it allows us to specify a password to use</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# yum install -y git wget unzip sshpass
Loaded plugins: fastestmirror
Setting up Install Process
Loading mirror speeds from cached hostfile
 * base: yum.tamu.edu
 * epel: fedora-epel.mirror.lstn.net
 * extras: centos.firehosted.com
 * updates: mirrors.adams.net
Package git-1.7.1-3.el6_4.1.x86_64 already installed and latest version
Package wget-1.12-5.el6_6.1.x86_64 already installed and latest version
Resolving Dependencies
--&gt; Running transaction check
---&gt; Package sshpass.x86_64 0:1.05-1.el6 will be installed
---&gt; Package unzip.x86_64 0:6.0-2.el6_6 will be installed
--&gt; Finished Dependency Resolution

Dependencies Resolved

============================================================
 Package     Arch       Version        Repository     Size
============================================================
Installing:
 sshpass     x86_64     1.05-1.el6     epel           19 k
 unzip       x86_64     6.0-2.el6_6    base           149 k

Transaction Summary
============================================================
Install       2 Package(s)

Total download size: 168 k
Installed size: 346 k
Downloading Packages:
(1/2): sshpass-1.05-1.el6.x86_64.rpm     |  19 kB     00:00
(2/2): unzip-6.0-2.el6_6.x86_64.rpm      | 149 kB     00:00
------------------------------------------------------------
Total                                                                                                                                                                     593 kB/s | 168 kB     00:00
warning: rpmts_HdrFromFdno: Header V3 RSA/SHA256 Signature, key ID 0608b895: NOKEY
Retrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6
Importing GPG key 0x0608B895:
 Userid : EPEL (6) &lt;epel@fedoraproject.org&gt;
 Package: epel-release-6-8.noarch (@extras)
 From   : /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6
Running rpm_check_debug
Running Transaction Test
Transaction Test Succeeded
Running Transaction
  Installing : sshpass-1.05-1.el6.x86_64     1/2
  Installing : unzip-6.0-2.el6_6.x86_64      2/2
  Verifying  : unzip-6.0-2.el6_6.x86_64      1/2
  Verifying  : sshpass-1.05-1.el6.x86_64     2/2

Installed:
  sshpass.x86_64 0:1.05-1.el6     unzip.x86_64 0:6.0-2.el6_6

Complete!
[root@packer-centos ~]#</code></pre></figure>

<h2>4. Install Packer</h2>

<p>Go to <a href="https://packer.io/downloads.html">https://packer.io/downloads.html</a> and copy the URL for the Linux 64-bit package. In the SSH session to our CentOS virtual machine, perform the following steps:</p>

<p>Create a new directory to install packer into</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# mkdir /usr/local/packer_0.8.6
[root@packer-centos ~]#</code></pre></figure>

<p>Download Packer using the URL you copied from the packer.io download page:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# wget https://releases.hashicorp.com/packer/0.8.6/packer_0.8.6_linux_amd64.zip
--2015-12-23 17:22:03--  https://releases.hashicorp.com/packer/0.8.6/packer_0.8.6_linux_amd64.zip
Resolving releases.hashicorp.com... 23.235.44.69
Connecting to releases.hashicorp.com|23.235.44.69|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 132616691 (126M) [application/zip]
Saving to: “packer_0.8.6_linux_amd64.zip”

100%[====================================&gt;] 132,616,691 6.97M/s   in 18s

2015-12-23 17:22:22 (6.95 MB/s) - “packer_0.8.6_linux_amd64.zip” saved [132616691/132616691]

[root@packer-centos ~]# unzip packer_0.8.6_linux_amd64.zip -d /usr/local/packer_8.6/
Archive:  packer_0.8.6_linux_amd64.zip
  inflating: /usr/local/packer_8.6/packer
  inflating: /usr/local/packer_8.6/packer-builder-amazon-chroot
  inflating: /usr/local/packer_8.6/packer-builder-amazon-ebs
  inflating: /usr/local/packer_8.6/packer-builder-amazon-instance
  inflating: /usr/local/packer_8.6/packer-builder-digitalocean
  inflating: /usr/local/packer_8.6/packer-builder-docker
  inflating: /usr/local/packer_8.6/packer-builder-file
  inflating: /usr/local/packer_8.6/packer-builder-googlecompute
  inflating: /usr/local/packer_8.6/packer-builder-null
  inflating: /usr/local/packer_8.6/packer-builder-openstack
  inflating: /usr/local/packer_8.6/packer-builder-parallels-iso
  inflating: /usr/local/packer_8.6/packer-builder-parallels-pvm
  inflating: /usr/local/packer_8.6/packer-builder-qemu
  inflating: /usr/local/packer_8.6/packer-builder-virtualbox-iso
  inflating: /usr/local/packer_8.6/packer-builder-virtualbox-ovf
  inflating: /usr/local/packer_8.6/packer-builder-vmware-iso
  inflating: /usr/local/packer_8.6/packer-builder-vmware-vmx
  inflating: /usr/local/packer_8.6/packer-post-processor-artifice
  inflating: /usr/local/packer_8.6/packer-post-processor-atlas
  inflating: /usr/local/packer_8.6/packer-post-processor-compress
  inflating: /usr/local/packer_8.6/packer-post-processor-docker-import
  inflating: /usr/local/packer_8.6/packer-post-processor-docker-push
  inflating: /usr/local/packer_8.6/packer-post-processor-docker-save
  inflating: /usr/local/packer_8.6/packer-post-processor-docker-tag
  inflating: /usr/local/packer_8.6/packer-post-processor-vagrant
  inflating: /usr/local/packer_8.6/packer-post-processor-vagrant-cloud
  inflating: /usr/local/packer_8.6/packer-post-processor-vsphere
  inflating: /usr/local/packer_8.6/packer-provisioner-ansible-local
  inflating: /usr/local/packer_8.6/packer-provisioner-chef-client
  inflating: /usr/local/packer_8.6/packer-provisioner-chef-solo
  inflating: /usr/local/packer_8.6/packer-provisioner-file
  inflating: /usr/local/packer_8.6/packer-provisioner-powershell
  inflating: /usr/local/packer_8.6/packer-provisioner-puppet-masterless
  inflating: /usr/local/packer_8.6/packer-provisioner-puppet-server
  inflating: /usr/local/packer_8.6/packer-provisioner-salt-masterless
  inflating: /usr/local/packer_8.6/packer-provisioner-shell
  inflating: /usr/local/packer_8.6/packer-provisioner-shell-local
  inflating: /usr/local/packer_8.6/packer-provisioner-windows-restart
  inflating: /usr/local/packer_8.6/packer-provisioner-windows-shell
[root@packer-centos ~]#</code></pre></figure>

<p>Update ~/.bashrc to add &quot;/usr/local/packer_8.6&quot; to our path. Run &quot;source ~/.bashrc&quot; to re-read ~/.bashrc and validate $PATH has been updated.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# echo &#39;export PATH=&quot;/usr/local/packer_8.6:$PATH&quot;&#39; &gt;&gt; ~/.bashrc
[root@packer-centos ~]# source ~/.bashrc
[root@packer-centos ~]# echo $PATH
/usr/local/packer_8.6:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin
[root@packer-centos ~]#</code></pre></figure>

<p>Ensure the packer binary can be found and is showing the proper version</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# which packer
/usr/local/packer_8.6/packer
[root@packer-centos ~]# packer -v
0.8.6
[root@packer-centos ~]#</code></pre></figure>

<h2>5. Stop the iptables firewall and disable it from started on reboot of the virtual machine</h2>

<p>Packer will start a web server service for providing kickstart and script files to Packer images during install. This service will use a random port within a range, so we will need to stop iptables in order to allow the Packer images to connect.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# service iptables stop
[root@packer-centos ~]# chkconfig iptables off
[root@packer-centos ~]#</code></pre></figure>

<h2>6. Install ovftool on the CentOS virtual machine</h2>

<p>Download linux 64bit version of ovftool 4.1 on your local machine</p>

<p><img src="/assets/01-download-ovftool-linux-64bit.png" alt="screenshot">  </p>

<p>SCP the downloaded file to the CentOS virtual machine</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">sdorsett-mbp:~ sdorsett$ scp ~/Downloads/VMware-ovftool-4.1.0-2459827-lin.x86_64.bundle root@192.168.1.52:/root/
root@192.168.1.52&#39;s password:
VMware-ovftool-4.1.0-2459827-lin.x86_64.bundle                    100%   37MB  12.4MB/s   00:03
sdorsett-mbp:~ sdorsett$</code></pre></figure>

<p>Install ovftool on the CentOS virtual machine and validate the version</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# ls
anaconda-ks.cfg  install.log  install.log.syslog  packer_0.8.6_linux_amd64.zip  VMware-ovftool-4.1.0-2459827-lin.x86_64.bundle
[root@packer-centos ~]# ./VMware-ovftool-4.1.0-2459827-lin.x86_64.bundle
Extracting VMware Installer...done.
You must accept the VMware OVF Tool component for Linux End User
License Agreement to continue.  Press Enter to proceed.
VMWARE END USER LICENSE AGREEMENT

PLEASE NOTE THAT THE TERMS OF THIS END USER LICENSE AGREEMENT SHALL GOVERN YOUR
USE OF THE SOFTWARE, REGARDLESS OF ANY TERMS THAT MAY APPEAR DURING THE
INSTALLATION OF THE SOFTWARE.

IMPORTANT-READ CAREFULLY:   BY DOWNLOADING, INSTALLING, OR USING THE SOFTWARE,
YOU (THE INDIVIDUAL OR LEGAL ENTITY) AGREE TO BE BOUND BY THE TERMS OF THIS END
USER LICENSE AGREEMENT (&quot;EULA&quot;).  IF YOU DO NOT AGREE TO THE TERMS OF THIS
EULA, YOU MUST NOT DOWNLOAD, INSTALL, OR USE THE SOFTWARE, AND YOU MUST DELETE
OR RETURN THE UNUSED SOFTWARE TO THE VENDOR FROM WHICH YOU ACQUIRED IT WITHIN
THIRTY (30) DAYS AND REQUEST A REFUND OF THE LICENSE FEE, IF ANY, THAT YOU PAID
FOR THE SOFTWARE.
...

Do you agree? [yes/no]: yes

The product is ready to be installed.  Press Enter to begin
installation or Ctrl-C to cancel.

Installing VMware OVF Tool component for Linux 4.1.0
    Configuring...
[######################################################################] 100%
Installation was successful.
[root@packer-centos ~]# which ovftool
/usr/bin/ovftool
[root@packer-centos ~]# ovftool -v
VMware ovftool 4.1.0 (build-2459827)
[root@packer-centos ~]#</code></pre></figure>

<h2>7. Install apache web server on the CentOS virtual machine</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# yum install -y httpd
Loaded plugins: fastestmirror
Setting up Install Process
Loading mirror speeds from cached hostfile
 * base: yum.tamu.edu
 * epel: fedora-epel.mirror.lstn.net
 * extras: centos.firehosted.com
 * updates: mirrors.adams.net
Resolving Dependencies
--&gt; Running transaction check
---&gt; Package httpd.x86_64 0:2.2.15-47.el6.centos.1 will be installed
--&gt; Processing Dependency: httpd-tools = 2.2.15-47.el6.centos.1 for package: httpd-2.2.15-47.el6.centos.1.x86_64
--&gt; Processing Dependency: apr-util-ldap for package: httpd-2.2.15-47.el6.centos.1.x86_64
--&gt; Processing Dependency: /etc/mime.types for package: httpd-2.2.15-47.el6.centos.1.x86_64
--&gt; Processing Dependency: libaprutil-1.so.0()(64bit) for package: httpd-2.2.15-47.el6.centos.1.x86_64
--&gt; Processing Dependency: libapr-1.so.0()(64bit) for package: httpd-2.2.15-47.el6.centos.1.x86_64
--&gt; Running transaction check
---&gt; Package apr.x86_64 0:1.3.9-5.el6_2 will be installed
---&gt; Package apr-util.x86_64 0:1.3.9-3.el6_0.1 will be installed
---&gt; Package apr-util-ldap.x86_64 0:1.3.9-3.el6_0.1 will be installed
---&gt; Package httpd-tools.x86_64 0:2.2.15-47.el6.centos.1 will be installed
---&gt; Package mailcap.noarch 0:2.1.31-2.el6 will be installed
--&gt; Finished Dependency Resolution

Dependencies Resolved

======================================================================
 Package        Arch       Version                  Repository   Size
======================================================================
Installing:
 httpd          x86_64     2.2.15-47.el6.centos.1   updates      830 k
Installing for dependencies:
 apr            x86_64     1.3.9-5.el6_2            base         123 k
 apr-util       x86_64     1.3.9-3.el6_0.1          base         87 k
 apr-util-ldap  x86_64     1.3.9-3.el6_0.1          base         15 k
 httpd-tools    x86_64     2.2.15-47.el6.centos.1   updates      77 k
 mailcap        noarch     2.1.31-2.el6             base         27 k

Transaction Summary
======================================================================
Install       6 Package(s)

Total download size: 1.1 M
Installed size: 3.6 M
Downloading Packages:
(1/6): apr-1.3.9-5.el6_2.x86_64.rpm                   | 123 kB  00:00
(2/6): apr-util-1.3.9-3.el6_0.1.x86_64.rpm            |  87 kB  00:00
(3/6): apr-util-ldap-1.3.9-3.el6_0.1.x86_64.rpm       |  15 kB  00:00
(4/6): httpd-2.2.15-47.el6.centos.1.x86_64.rpm        | 830 kB  00:00
(5/6): httpd-tools-2.2.15-47.el6.centos.1.x86_64.rpm  |  77 kB  00:00
(6/6): mailcap-2.1.31-2.el6.noarch.rpm                |  27 kB  00:00
----------------------------------------------------------------------
Total                                        711 kB/s | 1.1 MB  00:01
Running rpm_check_debug
Running Transaction Test
Transaction Test Succeeded
Running Transaction
  Installing : apr-1.3.9-5.el6_2.x86_64                         1/6
  Installing : apr-util-1.3.9-3.el6_0.1.x86_64                  2/6
  Installing : httpd-tools-2.2.15-47.el6.centos.1.x86_64        3/6
  Installing : apr-util-ldap-1.3.9-3.el6_0.1.x86_64             4/6
  Installing : mailcap-2.1.31-2.el6.noarch                      5/6
  Installing : httpd-2.2.15-47.el6.centos.1.x86_64              6/6
  Verifying  : httpd-tools-2.2.15-47.el6.centos.1.x86_64        1/6
  Verifying  : httpd-2.2.15-47.el6.centos.1.x86_64              2/6
  Verifying  : apr-util-ldap-1.3.9-3.el6_0.1.x86_64             3/6
  Verifying  : apr-1.3.9-5.el6_2.x86_64                         4/6
  Verifying  : mailcap-2.1.31-2.el6.noarch                      5/6
  Verifying  : apr-util-1.3.9-3.el6_0.1.x86_64                  6/6

Installed:
  httpd.x86_64 0:2.2.15-47.el6.centos.1

Dependency Installed:
  apr.x86_64 0:1.3.9-5.el6_2    apr-util.x86_64 0:1.3.9-3.el6_0.1    
  apr-util-ldap.x86_64 0:1.3.9-3.el6_0.1  httpd-tools.x86_64 0:2.2.15-47.el6.centos.1     
  mailcap.noarch 0:2.1.31-2.el6

Complete!
[root@packer-centos ~]#</code></pre></figure>

<h2>7. Remove the apache welcome.conf, to enable directory browsing, and start the httpd service</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# rm /etc/httpd/conf.d/welcome.conf
rm: remove regular file &#39;/etc/httpd/conf.d/welcome.conf&#39;? y
[root@packer-centos ~]# service httpd start
Starting httpd:                                            [  OK  ]
[root@packer-centos ~]#</code></pre></figure>

<h2>8. create the directory /var/www/html/box-files and test that the directory is visible in a browser</h2>

<p>Create the /var/www/hmlt/box-files/ directory and an empty test-file.txt</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# mkdir /var/www/html/box-files
[root@packer-centos ~]# touch /var/www/html/box-files/test-file.txt
[root@packer-centos ~]#</code></pre></figure>

<p>Open the ip address of the CentOS virtual machine in a browser and verify that the test-file.txt is visible</p>

<p><img src="/assets/02-browse-apache-box-file-directory.png" alt="screenshot">  </p>

<p>Delete /var/www/html/box-files/test-file.txt, since it will not be needed:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-centos ~]# rm /var/www/html/box-files/test-file.txt
rm: remove regular empty file &#39;/var/www/html/box-files/test-file.txt&#39;? y
[root@packer-centos ~]#</code></pre></figure>

<h3>That all for this post covering how to install Packer, ovftool and Apache web server on a CentOS virtual machine. In the next post we will create a Packer template that uses what we have setup so far.</h3>

<h3>Please provide any feedback or suggestions to my twitter account located on the about page.</h3>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2015/12/23/installing-esxi-virtual-machine-for-packer-depolyment/">
        Installing a ESXi 6.0 virtual machine for use with Packer
      </a>
    </h1>

    <span class="post-date">23 Dec 2015</span>

    <p>This is the second in a series of posts on <a href="https://sdorsett.github.io/2015/12/22/pipeline-for-creating-packer-box-files/">using a Packer pipeline to generate Vagrant .box files</a>.</p>

<p>In order to begin using Packer to create images, we will first need to lay the &quot;virtual&quot; ground work. Packer can create virtual machine images on a wide variety of virtualization or cloud platforms, but since I work for VMware I have been using the ESXi hypervisor.</p>

<ul>
<li>This post will be covering installing ESXi as a virtual machine on a vSphere cluster. There is no reason that you couldn&#39;t use Packer with a stand alone physical server that has ESXi installed as well.</li>
<li>These steps were performed using the vCenter 6.0 web client. You could just as well use ESXi 5 with the C# client, but the steps for setting up nested virtualization will be slightly different.</li>
<li>There is nothing new about the steps being covered, but I figured it would be best to go ahead and document them.</li>
<li>If you are looking for the best resources regarding running ESXi in a virtual machine, I would suggest taking a look at <a href="http://www.virtuallyghetto.com/">William Lam&#39;s blog</a> which covers this subject in great detail. Williams site also provides more details about the embedded host client we will be using.</li>
</ul>

<p>Let&#39;s get started...</p>

<h2>1. Log into the web client of your vCenter instance and create a new virtual machine.</h2>

<p>We first need to create a new virtual machine inside of which we will install the ESXi 6.0 hypervisor.</p>

<p><img src="/assets/01-new-virtual-machine.jpg" alt="screenshot">  </p>

<h2>2. Step through the new virtual machine wizard:</h2>

<p><img src="/assets/02-create-new-virtual-machine.jpg" alt="screenshot">  </p>

<p>Name the virtual machine what you would like and click next. I named mine &quot;packer-esxi&quot;.</p>

<p><img src="/assets/03-virtual-machine-name.jpg" alt="screenshot">  </p>

<p>Select the vCenter cluster or resource pool the virtual machine will reside in and click next.</p>

<p><img src="/assets/04-select-compute-resource.jpg" alt="screenshot">  </p>

<p>Select the datastore you want the ESXi virtual machine to be created on and click next. I&#39;m using a local datastore on one of my physical ESXi hosts, to prevent Packer from using storage shared across the entire cluster.</p>

<p><img src="/assets/05-select-storage.jpg" alt="screenshot">  </p>

<p>Select the compatibility (virtual hardware level) for the virtual machine and click next. I kept with the default of version 11.</p>

<p><img src="/assets/06-select-compatibility.jpg" alt="screenshot">  </p>

<p>Select the guest operating system. vSphere 6.0 or newer will allow you to select ESXi 6.0 as you guest OS. Click next. This is where things will be different if you are using vSphere 5.0 and the c# client since you will only have ESXi 5.0 listed as an option.</p>

<p><img src="/assets/07-select-guest-os.jpg" alt="screenshot">  </p>

<p>Customize to virtual hardware to have the necessary resources. I had created my ESXi vurtual machine with:</p>

<ul>
<li>2 vCPU</li>
<li>16 GB of memory</li>
<li>100GB virtual hard drive</li>
</ul>

<p><img src="/assets/08-customize-hardware.jpg" alt="screenshot">  </p>

<p>Make sure you expand CPU and enable &quot;Hardware virtualization.&quot; The ESXi installer will fail if this is not enabled.</p>

<p><img src="/assets/09-customize-hardware.jpg" alt="screenshot">  </p>

<p>Click finish to create the virtual machine.</p>

<p><img src="/assets/10-ready-to-complete.jpg" alt="screenshot">  </p>

<h2>3. Enable promiscuous mode on virtual portgroup being used by ESXi virtual machine</h2>

<p>You will need to ensure the portgroup (virtual network) you are connecting the ESXi virtual machine to has promiscuous mode enabled. Enabling promiscuous mode is required for the ESXi virtual machine to pass traffic to the child virtual machines running on it.</p>

<p><img src="/assets/29-enable-protgroup-promiscuous-mode.png" alt="screenshot"></p>

<h2>4. Connect the virtual CDROM of the ESXi virtual machine to the ESXi 6.0 installer .iso and power it on.</h2>

<p><img src="/assets/11-start-esxi-vm.jpg" alt="screenshot">  </p>

<h2>5. Connect to the console of the ESXi virtual machine and step through the installer</h2>

<p>Press enter to begin</p>

<p><img src="/assets/12-esxi-installer.jpg" alt="screenshot">  </p>

<p>Press F11 to accept the EULA</p>

<p><img src="/assets/13-esxi-installer.jpg" alt="screenshot">  </p>

<p>Select the 100GB virtual hard drive we created with the virtual machine</p>

<p><img src="/assets/14-esxi-installer.jpg" alt="screenshot">  </p>

<p>Select your keyboard layout and press enter</p>

<p><img src="/assets/15-esxi-installer.jpg" alt="screenshot">  </p>

<p>Enter the root password twice and press enter</p>

<p><img src="/assets/16-esxi-installer.jpg" alt="screenshot">  </p>

<p><img src="/assets/17-esxi-installer.jpg" alt="screenshot">  </p>

<p>Press F11 to begin the install process</p>

<p><img src="/assets/18-esxi-installer.jpg" alt="screenshot">  </p>

<p>Disconnect the .iso file from the virtual CDROM before rebooting the virtual machine</p>

<p><img src="/assets/19-esxi-installer.jpg" alt="screenshot">  </p>

<p><img src="/assets/20-esxi-installer.jpg" alt="screenshot">  </p>

<p><img src="/assets/21-esxi-post-install.jpg" alt="screenshot">  </p>

<h2>6. Press F2 to log into ESXi and make the following changes:</h2>

<ul>
<li>Set the management IP address, subnet mask and gateway</li>
<li>Set the hostname, dns servers and search domain</li>
<li>Enable ssh</li>
</ul>

<p><img src="/assets/22-set-ip-address.jpg" alt="screenshot">  </p>

<p><img src="/assets/23-apply-network-config.jpg" alt="screenshot">  </p>

<p><img src="/assets/24-enable-ssh.jpg" alt="screenshot">  </p>

<h2>7. On your local machine download the embedded host client .vib</h2>

<p>The embedded host client is a VMware fling that allows you to manage an ESXi host from a browser, without needing the #c client or vCenter. You can download the embedded host client .vib from <a href="https://labs.vmware.com/flings/esxi-embedded-host-client">this link</a>.</p>

<p><img src="/assets/25-download-embedded-host-client.jpg" alt="screenshot">  </p>

<h2>8. SCP the downloaded .vib to the ESXi virtual machine</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">sdorsett-mbp:~ sdorsett$ scp ~/Downloads/esxui_signed.vib root@192.168.1.51:/tmp/
The authenticity of host &#39;192.168.1.51 (192.168.1.51)&#39; cant be established.
RSA key fingerprint is 82:e9:6b:9e:9d:ac:d7:8a:65:e2:9e:bf:60:fc:2b:df.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added &#39;192.168.1.51&#39; (RSA) to the list of known hosts.
Password: ********
esxui_signed.vib                                                                                                                                100% 2805KB   2.7MB/s   00:00
sdorsett-mbp:~ sdorsett$</code></pre></figure>

<h2>9. SSH to the ESXi virtual machine and install the embedded host client .vib</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">sdorsett-mbp:~ sdorsett$ ssh root@192.168.1.51
Password: ********
The time and date of this login have been sent to the system logs.

VMware offers supported, powerful system administration tools.  Please
see www.vmware.com/go/sysadmintools for details.

The ESXi Shell can be disabled by an administrative user. See the
vSphere Security documentation for more information.

[root@packer-esxi:~] cd tmp
[root@packer-esxi:/tmp] ls
esxui_signed.vib  nfsgssd_krb5cc    probe.session     vmware-root

[root@packer-esxi:/tmp] esxcli software vib install -v /tmp/esxui_signed.vib
Installation Result
   Message: Operation finished successfully.
   Reboot Required: false
   VIBs Installed: VMware_bootbank_esx-ui_0.0.2-0.1.3357452
   VIBs Removed:
   VIBs Skipped:

[root@packer-esxi:/tmp]</code></pre></figure>

<h2>10. Enable guest ip hack on the ESXi virtual machine</h2>

<p>The <a href="https://www.packer.io/docs/builders/vmware-iso.html">Packer VMware .iso builder documentation</a> lists the following esxcli command as needing to be run on the ESXi virtual machine:</p>

<p><img src="/assets/28-enable-guest-ip-hack.jpg" alt="screenshot">  </p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@packer-esxi:/tmp] esxcli system settings advanced set -o /Net/GuestIPHack -i 1
[root@packer-esxi:/tmp] exit
Connection to 192.168.1.51 closed.
sdorsett-mbp:~ sdorsett$</code></pre></figure>

<h2>11. Log into the embedded host client to validate that it it working properly</h2>

<p>Open a browser on your local machine and go to https://[ESXi-virtual-machine-ip-address]/ui<br>
Accept any certificate warnings and log in using root as the username and the password you entered while installing ESXi.</p>

<p><img src="/assets/26-embedded-host-client.jpg" alt="screenshot">  </p>

<p>Under Storage | Datastores we can see a datastore name &quot;datastore1&quot; was automatically created using the extra space of the virtual hard drive.</p>

<p><img src="/assets/27-embedded-host-client.jpg" alt="screenshot">  </p>

<h3>That all for this post covering how to create a ESXi virtual machine that we will use to create Packer images.</h3>

<h3>Please provide any feedback or suggestions to my twitter account located on the about page.</h3>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2015/12/22/pipeline-for-creating-packer-box-files/">
        Setting up a pipeline for creating Packer .box files
      </a>
    </h1>

    <span class="post-date">22 Dec 2015</span>

    <p>Recently at work, the vCloud Air Zombie team has been using Packer to generate Vagrant templates for use in development and testing.  I have previously covered <a href="https://sdorsett.github.io/2015/01/03/using-packer-on-centos/">how to use Packer to create create a .box template for use with Vagrant</a>, but I thought it might be useful to others to demonstrate how we are using Packer to create images.</p>

<p>This will be the first of several blog posts in which I intend to cover:</p>

<ul>
<li><a href="https://sdorsett.github.io/2015/12/23/installing-esxi-virtual-machine-for-packer-depolyment/">Installing a ESXi 6.0 virtual machine for use with Packer</a> - this is where Packer will be creating the virtual machine image.</li>
<li><a href="https://sdorsett.github.io/2015/12/24/installing-packer-and-ovftool-on-centos/">Setting up Packer, ovftool and Apache web server on a CentOS virtual machine</a> - this will be where we will be editing and running the Packer templates.</li>
<li><a href="https://sdorsett.github.io/2015/12/25/creating-a-packer-template-for-installing-centos-67/">Creating our first Packer template for installing CentOS 6.7 with vmtools</a> - templates are the instructions for how a Packer image should be built.</li>
<li><a href="https://sdorsett.github.io/2015/12/26/copy-our-existing-template-and-add-the-puppet-agent/">Copying our existing CentOS 6.7 template and adding the Puppet agent</a> - having the puppet agent in an image allows us to use puppet to describe configurations using puppet in either Packer and Vagrant.</li>
<li><a href="https://sdorsett.github.io/2015/12/27/using-ovftool-to-export-packer-generated-virtual-machines/">Using ovftool to convert Packer generated virtual machines into Vagrant .box files</a> - ovftool allows you to export the Packer created images in either a Fusion or vSphere compatible format.</li>
<li><a href="https://sdorsett.github.io/2015/12/28/scripted-packer-build-and-export/">Scripted Packer build, ovftool export and Vagrant .box file creation</a> - pulling everything we have done with Packer template creation and ovftool export into a single script</li>
</ul>

<p>I have also created a github repository to contain the Packer configuration files using during this series. You can access the github repository at <a href="https://github.com/sdorsett/packer-templates">https://github.com/sdorsett/packer-templates</a>.</p>

<p>These posts will hopefully be helpful by providing details on the process of using Packer to generate Vagrant .box files.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2015/01/06/creating-vcsa-box-manually/">
        Creating a vCSA 5.5 .box template on CentOS 6.5 for vagrant deployment
      </a>
    </h1>

    <span class="post-date">06 Jan 2015</span>

    <p>In the last few blogs post we have created ESXi .box templates, but in order to create a complete virtual lab using vagrant we will also need a vCenter Server Appliance virtual machine. The vCSA comes as a .ova template, so we will need to convert it to a vagrant-vmware-ovf .box template before we can use it with vagrant.</p>

<p>In this post we will need several packages installed, that we have covered in the last few posts:</p>

<ul>
<li>vagrant - I used vagrant 1.7.1 for these steps</li>
<li><a href="https://github.com/gosddc/vagrant-vcenter">gosddc/vagrant-vcenter</a>.
This repo contains a vagrant plugin (provider) that will deploy a vagrant-vmware-ovf generated .box template to a vcenter instance. This provider allows vagrant to seamlessly deploy to vCenter.</li>
<li>ovftool - I have ovftool 3.5.1 installed on my CentOS vm.</li>
</ul>

<p>I will be using the same CentOS virtual machine we used <a href="https://sdorsett.github.io/2015/01/04/installing-vagrant-on-centos/">in the last post</a> since it already has all the packages we will be needing.</p>

<h2>1. Download the vCenter Server Appliance .iso from the <a href="https://my.vmware.com/web/vmware/details?downloadGroup=VC55U2&productId=353">vmware.com download page</a>.</h2>

<p>I will be using &quot;VMware-vCenter-Server-Appliance-5.5.0.20000-2063318_OVF10.ova&quot;, which is the vCSA 5.5 U2 .ova. </p>

<h2>2. Use ovftool to upload the vCSA .ova to vCenter:</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant ~]# ovftool --disableVerification  --noSSLVerify --datastore=esx01-local-sata --name=vcsa-5.5.0.20000-2063318 --network=vlan2 ~/VMware-vCenter-Server-Appliance-5.5.0.20000-2063318_OVF10.ova vi://root@192.168.1.201
Opening OVA source: VMware-vCenter-Server-Appliance-5.5.0.20000-2063318_OVF10.ova
The manifest validates
Enter login information for target vi://192.168.1.201/
Username: root
Password: **********
Opening VI target: vi://root@192.168.1.201:443/
Deploying to VI: vi://root@192.168.1.201:443/
Transfer Completed
Completed successfully
[root@vagrant ~]#</code></pre></figure>

<p>You will need to modify the following parameters in the ovftool command:</p>

<ul>
<li>--datastore - this is the datastore that ovftool will deploy the virtual machine to</li>
<li>--name - this is the name the deployed virtual machine will be given</li>
<li>--network - this is the portgroup the deployed virtual machine will be connected to</li>
<li>vi://root://[esxi_host_ip_address] - update this part of the command with the IP address of one of your ESXi servers</li>
</ul>

<h2>3. Modify the vCSA virtual machine for vagrant deployment.</h2>

<h4>A. Power on the vcsa-5.5.0.20000-2063318 virtual machine in the VI or vSphere web client.</h4>

<h4>B. Once the vCSA virtual machine is up and running, SSH to the IP address that is acquired by DHCP.</h4>

<h5>C. Create the ~/.ssh directory</h5>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">localhost:~ # mkdir ~/.ssh</code></pre></figure>

<h4>D. Add the vagrant public ssh key to ~/.ssh/authorized_keys:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">localhost:~ # cd .ssh
localhost:~/.ssh # echo &#39;ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ== vagrant insecure public key&#39; &gt; ~/.ssh/authorized_keys</code></pre></figure>

<h4>E. Modify the permissions on ~/.ssh &amp; ~/.ssh/authorized_keys since openssh is particular about file permissions:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">localhost:~/.ssh # chmod 700 ~/.ssh
localhost:~/.ssh # chmod 600 ~/.ssh/authorized_keys</code></pre></figure>

<h4>F. Modify the following lines in /etc/ssh/sshd_config:</h4>

<p>Uncomment and update the following lines:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">PubkeyAuthentication yes                  # line 47
AuthorizedKeysFile ~/.ssh/authorized_keys # line 48</code></pre></figure>

<p>Comment out the following line:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">#MaxSessions 1                            # line 44</code></pre></figure>

<h4>G. Power down the vcsa-5.5.0.20000-2063318 virtual machine in the VI or vSphere web client.</h4>

<h2>4. Use ovftool to export the vcsa-5.5.0.20000-2063318 virtual machine.</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant ~]# ovftool vi://root@192.168.1.201/vcsa-5.5.0.20000-2063318 ./
Enter login information for source vi://192.168.1.201/
Username: root
Password: **********
Opening VI source: vi://root@192.168.1.201:443/vcsa-5.5.0.20000-2063318
Opening OVF target: ./
Writing OVF package: ./vcsa-5.5.0.20000-2063318/vcsa-5.5.0.20000-2063318.ovf
Transfer Completed
Completed successfully</code></pre></figure>

<p>&quot;vi://root@192.168.1.201&quot; will need to be updated to use the IP address of the ESXi host that has your vcsa-5.5.0.20000-2063318 virtual machine.</p>

<h2>5. add the additional vagrant-vmware-ovf files and tar up the vcsa-5.5.0.20000-2063318 .ovf as a .box file:</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant ~]# cd vcsa-5.5.0.20000-2063318/
[root@vagrant vcsa-5.5.0.20000-2063318]# echo &#39;{&quot;provider&quot;:&quot;vmware_ovf&quot;}&#39; &gt;&gt; metadata.json
[root@vagrant vcsa-5.5.0.20000-2063318]# touch Vagrantfile
[root@vagrant vcsa-5.5.0.20000-2063318]# tar cvzf vcsa-5.5.0.20000-2063318-vmware_ovf-1.0.box ./*
./metadata.json
./Vagrantfile
./vcsa-5.5.0.20000-2063318-disk1.vmdk
./vcsa-5.5.0.20000-2063318-disk2.vmdk
./vcsa-5.5.0.20000-2063318.mf
./vcsa-5.5.0.20000-2063318.ovf
[root@vagrant vcsa-5.5.0.20000-2063318]#</code></pre></figure>

<h2>6. Create a directory to keep our vagrant-vmware-ovf .box template in and move the vCSA template to it:</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant vcsa-5.5.0.20000-2063318]# mkdir ~/box-files/
[root@vagrant vcsa-5.5.0.20000-2063318]# mv vcsa-5.5.0.20000-2063318-vmware_ovf-1.0.box ~/box-files/</code></pre></figure>

<h4>C. Create directory and Vagrantfile for the vCSA virtual machines we will deploy with vagrant:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant vcsa-5.5.0.20000-2063318]# mkdir -p ~/vagrant-vms/vcsa-test/
[root@vagrant vcsa-5.5.0.20000-2063318]# cd ~/vagrant-vms/vcsa-test/
[root@vagrant vcsa-test]# vi Vagrantfile
[root@vagrant vcsa-test]# cat Vagrantfile
vcsa_box_url = &#39;/root/box-files/vcsa-5.5.0.20000-2063318-vmware_ovf-1.0.box&#39;

$script = &lt;&lt;SCRIPT
#!/bin/bash
# Commands to configure all the necessary services to start the vCenter Service, thanks @lamw ! see:
# http://www.virtuallyghetto.com/2012/02/automating-vcenter-server-appliance.html
 
echo &quot;Accepting EULA ...&quot;
/usr/sbin/vpxd_servicecfg eula accept
 
echo &quot;Configuring Embedded DB ...&quot;
/usr/sbin/vpxd_servicecfg db write embedded
 
echo &quot;Configuring SSO...&quot;
/usr/sbin/vpxd_servicecfg sso write embedded
 
echo &quot;Starting VCSA ...&quot;
/usr/sbin/vpxd_servicecfg service start

# http://www.virtuallyghetto.com/2014/02/how-to-automate-ntp-configurations-on.html
/usr/sbin/vpxd_servicecfg timesync write ntp &#39;pool.ntp.org&#39; &#39;&#39;

# Command to set IP address to 192.168.1.81:
# http://www.virtuallyghetto.com/2013/02/automating-vcsa-network-configurations.html
echo &quot;Setting static IP address to 192.168.1.81&quot;
/opt/vmware/share/vami/vami_set_network eth0 STATICV4 192.168.1.81 255.255.255.0 192.168.1.1 &gt;&amp;- 2&gt;&amp;- &lt;&amp;- &amp;
SCRIPT

nodes = [
  { :hostname =&gt; &#39;vcsa-01a&#39;, :box =&gt; &#39;vcsa-5.5.0.20000-2063318&#39;, :box_url =&gt; vcsa_box_url}
]
 
Vagrant.configure(&#39;2&#39;) do |config|
 
  config.vm.provider :vcenter do |vcenter|
    vcenter.hostname = &#39;192.168.1.195&#39;
    vcenter.username = &#39;root&#39;
    vcenter.password = &#39;mySecretP@ssw0rd&#39;
    vcenter.folder_name = &#39;Vagrant/Deployed&#39;
    vcenter.datacenter_name = &#39;datacenter-01&#39;
    vcenter.computer_name = &#39;cluster-01&#39;
    vcenter.datastore_name = &#39;vsanDatastore&#39;
    vcenter.template_folder_name = &#39;Vagrant/Templates&#39;
    vcenter.network_name = &#39;vlan2&#39;
    vcenter.linked_clones = true
    vcenter.enable_vm_customization = false
  end
 
  # Go through nodes and configure each of them.j
  nodes.each do |node|
    config.vm.define node[:hostname] do |node_config|
 
      if node[:hostname].include? &#39;vcsa-&#39;
        node_config.ssh.username = &#39;root&#39;
        node_config.ssh.insert_key = false
        node_config.vm.synced_folder &#39;.&#39;, &#39;/vagrant&#39;, disabled: true
        node_config.vm.provision &quot;shell&quot;, inline: $script
      end 
      node_config.vm.box = node[:box]
      node_config.vm.hostname = node[:hostname]
      node_config.vm.box_url = node[:box_url]
    end
  end
end</code></pre></figure>

<p>This Vagrantfile is specifying vagrant to use the vagrant-vcenter profiler to create one virtual machine (vcsa-01a) from the vcsa-5.5.0.20000-2063318-vmware_ovf-1.0.box file. You will need update the following properties to reflect your own vCenter configuration:</p>

<ul>
<li>vcenter.hostname = the IP address of your vCenter server</li>
<li>vcenter.username = the username used to connect to your vCenter server</li>
<li>vcenter.password = the password used to connect to your vCenter server</li>
<li>vcenter.datacenter_name = the vCenter virtual datacenter to use for virtual machine deployment</li>
<li>vcenter.computer_name = the vCenter host or cluster to use for virtual machine deployment. I&#39;ve used the cluster in my example.</li>
<li>vcenter.datastore_name = the vCenter datastore to use for virtual machine deployment</li>
<li>vcenter.folder_name = the vm folder that the virtual machines will be deployed to</li>
<li>vcenter.template_folder_name = the vm folder that the vCSA template will be created in</li>
<li>vcenter.network_name = the vCenter portgroup to connect the vCSA template to. There should be a DHCP server on this portgroup to provide IP addresses to the deployed vCSA template.</li>
</ul>

<p>There is also a script section at the top of the Vagrantfile I would like to point out. William Lam has posted several posts documenting how to automate vCSA configuration, and several of his suggestions have been included in this section. Namely those are:</p>

<ul>
<li>Accepting the EULA</li>
<li>Configuring the vCSA to use the internal database</li>
<li>Configuring internal SSO</li>
<li>Starting the vCenter services</li>
<li>Setting NTP</li>
<li>Assigning a static IP address using vami_set_network command</li>
</ul>

<p>You might want to adjust the last part of the script, since it will set vCSA to use 192.168.1.81 as it&#39;s static IP address. </p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">echo &quot;Setting static IP address to 192.168.1.81&quot;
/opt/vmware/share/vami/vami_set_network eth0 STATICV4 192.168.1.81 255.255.255.0 192.168.1.1 &gt;&amp;- 2&gt;&amp;- &lt;&amp;- &amp;</code></pre></figure>

<p>I prefer to set a static address for the vCSA, so that any scripts that follow the vCSA deployment will know exactly what IP address to use to connect to it. Also you might be wondering about extra characters following the VAMI command. Since this command is modifying the IP address of the virtual machine, we&#39;re need to run this command in the background without expecting a response. Here the breakdown of what is being done:</p>

<ul>
<li>&gt;&amp;- means close stdout.</li>
<li>2&gt;&amp;- means close stderr.</li>
<li>&lt;&amp;- means close stdin.</li>
<li>&amp; means run in the background</li>
</ul>

<p>If we didn&#39;t pipe the vami_set_network command through these commands, vagrant would keep waiting on output in the SSH session that the command was successfully run, but the IP address had been changed so it would never receive the expected response. </p>

<h2>4. &quot;vagrant up&quot;</h2>

<h4>A. Now that we have created a Vagrantfile config file and updated it with our vCenter information we can bring up our virtual machine by running &quot;vagrant up&quot; in the directory with the Vagrantfile.</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant vcsa-test]# vagrant up
Bringing machine &#39;vcsa-01a&#39; up with &#39;vcenter&#39; provider...
==&gt; vcsa-01a: Creating VM...
==&gt; vcsa-01a: Powering on VM...
==&gt; vcsa-01a: Running provisioner: shell...
    vcsa-01a: Running: inline script
==&gt; vcsa-01a: Accepting EULA ...
==&gt; vcsa-01a: VC_CFG_RESULT=0
==&gt; vcsa-01a: Configuring Embedded DB ...
==&gt; vcsa-01a: insserv: Service network is missed in the runlevels 4 to use service postgresql
==&gt; vcsa-01a: insserv: Service syslog is missed in the runlevels 4 to use service postgresql
==&gt; vcsa-01a: VC_DB_SCHEMA_VERSION=VirtualCenter Database 5.5
==&gt; vcsa-01a: VC_DB_SCHEMA_INITIALIZED=1
==&gt; vcsa-01a: VC_CFG_RESULT=0
==&gt; vcsa-01a: Configuring SSO...
==&gt; vcsa-01a: VC_CFG_RESULT=0
==&gt; vcsa-01a: Starting VCSA ...
==&gt; vcsa-01a: VC_CFG_RESULT=0
==&gt; vcsa-01a: insserv: Service network is missed in the runlevels 4 to use service postgresql
==&gt; vcsa-01a: insserv: Service syslog is missed in the runlevels 4 to use service postgresql
==&gt; vcsa-01a: VC_CFG_RESULT=0
==&gt; vcsa-01a: Setting static IP address to 192.168.1.81
[root@vagrant vcsa-test]#</code></pre></figure>
 

<h4>B. Once the &quot;vagrant up&quot; command completes, you can check the status of the vCSA vm using &quot;vagrant status&quot;:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant vcsa-test]# vagrant status
Current machine states:

vcsa-01a                  running (vcenter)

The VM is running. To stop this VM, you can run `vagrant halt` to
shut it down forcefully, or you can run `vagrant suspend` to simply
suspend the virtual machine. In either case, to restart it again,
simply run `vagrant up`.
[root@vagrant vcsa-test]#</code></pre></figure>

<h4>D. You can now ssh into the vCSA virtual machine using &quot;vagrant ssh&quot;:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant vcsa-test]# vagrant ssh
==&gt; vcsa-01a: External IP for vcsa-01a: 192.168.1.81
Last login: Sat Jan 10 20:08:07 UTC 2015 from 192.168.1.24 on pts/0
Last login: Sat Jan 10 20:09:36 2015 from 192.168.1.24
localhost:~ # service vmware-vpxd status
vmware-vpxd is running
tomcat is running
localhost:~ # exit
logout
Connection to 192.168.1.81 closed.
[root@vagrant vcsa-test]#</code></pre></figure>

<p>I wanted to point out that vagrant automatically detected up the IP address change we made through vmtools, so we didn&#39;t have to perform any additional steps for &quot;vagrant ssh&quot; to work.</p>

<h4>E. Once we are done using our virtual machine, it can be destroyed with a &quot;vagrant destroy&quot; command:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant vcsa-test]# vagrant destroy
    vcsa-01a: Are you sure you want to destroy the &#39;vcsa-01a&#39; VM? [y/N] y
==&gt; vcsa-01a: Powering off VM...
==&gt; vcsa-01a: Destroying VM...
[root@vagrant vcsa-test]#</code></pre></figure>

<h4>F. If you are ever unsure of the state of the vagrant virtual machine you can run &quot;vagrant status&quot; to check:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant vcsa-test]# vagrant status
Current machine states:

vcsa-01a                  not created (vcenter)

The environment has not yet been created. Run `vagrant up` to
create the environment. If a machine is not created, only the
default provider will be shown. So if a provider is not listed,
then the machine is not created for that environment.
[root@vagrant vcsa-test]#</code></pre></figure>

<h3>That all for this post covering how to create a vCSA .box template and deploy it using the vagrant-vcenter provider.</h3>

<h3>Please provide any feedback or suggestions to my twitter account located on the about page.</h3>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2015/01/04/installing-vagrant-on-centos/">
        Installing vagrant and the vagrant-vcenter provider on CentOS 6.5
      </a>
    </h1>

    <span class="post-date">04 Jan 2015</span>

    <p>If you followed the steps in one of the two previous posts, you have a ESXi .box template in the vagrant-vmware-ovf format. This format allows for deploying the exact same template to vCenter, vCloud Director or vCloud Air, by simply specifying a different provider in vagrant. This post will cover deploying to vCenter, since that is the most readily available of the three. </p>

<p>In this post we will again talk about the following helpful gosddc project:</p>

<ul>
<li><a href="https://github.com/gosddc/vagrant-vcenter">gosddc/vagrant-vcenter</a>.
This repo contains a vagrant plugin (provider) that will deploy a vagrant-vmware-ovf generated .box template to a vcenter instance. This provider allows vagrant to seamlessly deploy to vCenter.</li>
</ul>

<p>We will need a virtual machine with a minimal install of CentOS 6.5 to install vagrant or you can use the same CentOS virtual machine we used <a href="https://sdorsett.github.io/2015/01/03/using-packer-on-centos/">in the last post</a>. For convenience I will be using the same virtual machine.</p>

<h2>1. Let&#39;s get started by installing the necessary dependancies.</h2>

<h4>A. Run the following command to install the some needed packages:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant ~]# yum install -y gcc-c++ glibc-headers openssl-devel readline libyaml-devel readline-devel zlib zlib-devel iconv-devel libxml2 libxml2-devel libxslt libxslt-devel wget git unzip</code></pre></figure>

<h4>B. Download and install ruby-build:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant ~]# git clone https://github.com/sstephenson/ruby-build.git
Initialized empty Git repository in /root/ruby-build/.git/
remote: Counting objects: 4212, done.
remote: Compressing objects: 100% (16/16), done.
remote: Total 4212 (delta 4), reused 2 (delta 0)
Receiving objects: 100% (4212/4212), 761.14 KiB | 730 KiB/s, done.
Resolving deltas: 100% (2142/2142), done.
[root@vagrant ~]# cd ruby-build/
[root@vagrant ruby-build]# ./install.sh</code></pre></figure>

<h4>C. Running the &quot;ruby-build --definitions&quot; command will provide an output of the versions of Ruby that ruby-buid supports:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant ruby-build]# ruby-build --definitions
1.8.6-p383
1.8.6-p420
1.8.7-p249
1.8.7-p302
1.8.7-p334
1.8.7-p352
1.8.7-p357
1.8.7-p358
1.8.7-p370
1.8.7-p371
1.8.7-p374
1.8.7-p375
1.9.1-p378
1.9.1-p430
1.9.2-p0
1.9.2-p180
1.9.2-p290
1.9.2-p318
1.9.2-p320
1.9.2-p326
1.9.2-p330
1.9.3-dev
1.9.3-preview1
1.9.3-rc1
1.9.3-p0
1.9.3-p125
1.9.3-p194
1.9.3-p286
1.9.3-p327
1.9.3-p362
1.9.3-p374
1.9.3-p385
1.9.3-p392
1.9.3-p429
1.9.3-p448
1.9.3-p484
1.9.3-p545
1.9.3-p547
1.9.3-p550
1.9.3-p551
2.0.0-dev
2.0.0-preview1
2.0.0-preview2
...</code></pre></figure>

<h4>D. Install ruby 1.9.3 build 551 using the following command:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant ruby-build]# ruby-build 1.9.3-p551 /usr/local/
Downloading yaml-0.1.6.tar.gz...
-&gt; http://dqw8nmjcqpjn7.cloudfront.net/7da6971b4bd08a986dd2a61353bc422362bd0edcc67d7ebaac68c95f74182749
Installing yaml-0.1.6...
Installed yaml-0.1.6 to /usr/local/

Downloading ruby-1.9.3-p551.tar.gz...
-&gt; http://dqw8nmjcqpjn7.cloudfront.net/bb5be55cd1f49c95bb05b6f587701376b53d310eb1bb7c76fbd445a1c75b51e8
Installing ruby-1.9.3-p551...
Installed ruby-1.9.3-p551 to /usr/local/</code></pre></figure>

<h4>E. Download and install the latest version of ruby gems. You can always find the URL to the most recent version at <a href="https://rubygems.org/pages/download">rubygems.org</a>.</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant ruby-build]# cd ~/
[root@vagrant ~]# wget http://production.cf.rubygems.org/rubygems/rubygems-2.4.5.tgz
--2015-01-02 21:14:39-- http://production.cf.rubygems.org/rubygems/rubygems-2.4.5.tgz
Resolving production.cf.rubygems.org... 54.230.6.155, 54.230.6.120, 54.230.7.122, ...
Connecting to production.cf.rubygems.org|54.230.6.155|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 446665 (436K) [application/x-tar]
Saving to: &quot;rubygems-2.4.5.tgz&quot;

100%[==================================================================================================&gt;] 446,665 1.78M/s in 0.2s 

2015-01-02 21:14:45 (1.78 MB/s) - &quot;rubygems-2.4.5.tgz&quot; saved [446665/446665]

[root@vagrant ~]# tar -zxf rubygems-2.4.5.tgz
[root@vagrant ~]# cd rubygems-2.4.5
[root@vagrant rubygems-2.4.5]# ruby setup.rb
RubyGems 2.4.5 installed
Installing ri documentation for rubygems-2.4.5</code></pre></figure>

<h2>2. Create a directory to keep our vagrant-vmware-ovf .box template to and copy the template we previously created to it:</h2>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant esxi55]# mkdir ~/box-files/
[root@vagrant esxi55]# cp /root/packer/packer-templates/esxi55/esxi55-vmware_ovf-1.1.box ~/box-files/</code></pre></figure>

<h2>3. The next thing we need to do is download and install vagrant and the vagrant-vcenter provider:</h2>

<h4>A. Download and install the latest version of vagrant. You can find the URL to the latest versions of the linux 64bit .rpm at <a href="https://www.vagrantup.com/downloads.html">vagrantup.com</a>.</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant rubygems-2.4.5]# cd ~/
[root@vagrant ~]# wget https://dl.bintray.com/mitchellh/vagrant/vagrant_1.7.1_x86_64.rpm
--2015-01-03 16:02:34-- https://dl.bintray.com/mitchellh/vagrant/vagrant_1.7.1_x86_64.rpm
Resolving dl.bintray.com... 108.168.194.92, 108.168.194.91
Connecting to dl.bintray.com|108.168.194.92|:443... connected.
HTTP request sent, awaiting response... 302 
Resolving d29vzk4ow07wi7.cloudfront.net... 54.230.7.101, 54.230.5.129, 54.230.6.222, ...
Connecting to d29vzk4ow07wi7.cloudfront.net|54.230.7.101|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 65197711 (62M) [application/unknown]
Saving to: &quot;vagrant_1.7.1_x86_64.rpm&quot;

100%[==================================================================================================&gt;] 65,197,711 1.92M/s in 33s 

2015-01-03 16:03:18 (1.87 MB/s) - &quot;vagrant_1.7.1_x86_64.rpm&quot; saved [65197711/65197711]

[root@vagrant ~]# rpm -i vagrant_1.7.1_x86_64.rpm
[root@vagrant ~]# vagrant -v
Vagrant 1.7.1</code></pre></figure>

<h4>B. Install the vagrant-vcenter plugin using the following commands:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant ~]# vagrant plugin list
vagrant-share (1.1.4, system)
[root@vagrant ~]# vagrant plugin install vagrant-vcenter
Installing the &#39;vagrant-vcenter&#39; plugin. This can take a few minutes...
Installed the plugin &#39;vagrant-vcenter (0.3.2)&#39;!
[root@vagrant ~]#</code></pre></figure>

<h4>C. Create directory and Vagrantfile for the ESXi virtual machines we will deploy with vagrant:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant ~]# mkdir -p ~/vagrant-vms/esxi-test/
[root@vagrant ~]# cd vagrant-vms/esxi-test/
[root@vagrant esxi-test]# vi Vagrantfile
[root@vagrant esxi-test]# cat Vagrantfile
esxi_box_url = &#39;/root/box-files/esxi55-vmware_ovf-1.1.box&#39;
 
nodes = [
  { :hostname =&gt; &#39;esx-01a&#39;, :box =&gt; &#39;esxi55&#39;, :box_url =&gt; esxi_box_url},
  { :hostname =&gt; &#39;esx-02a&#39;, :box =&gt; &#39;esxi55&#39;, :box_url =&gt; esxi_box_url},
]
 
Vagrant.configure(&#39;2&#39;) do |config|
 
  config.vm.provider :vcenter do |vcenter|
    vcenter.hostname = &#39;192.168.1.195&#39;
    vcenter.username = &#39;root&#39;
    vcenter.password = &#39;mySecretP@ssw0rd&#39;
    vcenter.folder_name = &#39;Vagrant/Deployed&#39;
    vcenter.datacenter_name = &#39;datacenter-01&#39;
    vcenter.computer_name = &#39;cluster-01&#39;
    vcenter.datastore_name = &#39;vsanDatastore&#39;
    vcenter.template_folder_name = &#39;Vagrant/Templates&#39;
    vcenter.network_name = &#39;vlan2&#39;
    vcenter.linked_clones = true
    vcenter.enable_vm_customization = false
  end
 
  # Go through nodes and configure each of them.j
  nodes.each do |node|
    config.vm.define node[:hostname] do |node_config|
 
      if node[:hostname].include? &#39;esx-&#39;
        node_config.ssh.username = &#39;root&#39;
        node_config.ssh.shell = &#39;sh&#39;
        node_config.ssh.insert_key = false
        node_config.vm.synced_folder &#39;.&#39;, &#39;/vagrant&#39;, disabled: true
      end
 
      node_config.vm.box = node[:box]
      node_config.vm.hostname = node[:hostname]
      node_config.vm.box_url = node[:box_url]
    end
  end
end</code></pre></figure>

<p>This Vagrantfile is specifying vagrant to use the vagrant-vcenter profiler to create two virtual machines (esx-01a &amp; esx-02a) from the esx55-vmware_ovf-1.1.box file. You will need update the following properties to reflect your own vCenter configuration:</p>

<ul>
<li>vcenter.hostname = the IP address of your vCenter server</li>
<li>vcenter.username = the username used to connect to your vCenter server</li>
<li>vcenter.password = the password used to connect to your vCenter server</li>
<li>vcenter.datacenter_name = the vCenter virtual datacenter to use for virtual machine deployment</li>
<li>vcenter.computer_name = the vCenter host or cluster to use for virtual machine deployment. I&#39;ve used the cluster in my example.</li>
<li>vcenter.datastore_name = the vCenter datastore to use for virtual machine deployment</li>
<li>vcenter.folder_name = the vm folder that the virtual machines will be deployed to</li>
<li>vcenter.template_folder_name = the vm folder that the ESXi template will be created in</li>
<li>vcenter.network_name = the vCenter portgroup to connect the ESXi templates to. There should be a DHCP server on this portgroup to provide IP addresses to the deployed ESXi templates.</li>
</ul>

<h2>4. &quot;vagrant up&quot;</h2>

<h4>A. Now that we have created a Vagrantfile config file and updated it with our vCenter information we can bring up our virtual machine by running &quot;vagrant up&quot; in the directory with the Vagrantfile.</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant esxi-test]# vagrant up
Bringing machine &#39;esx-01a&#39; up with &#39;vcenter&#39; provider...
Bringing machine &#39;esx-02a&#39; up with &#39;vcenter&#39; provider...
==&gt; esx-01a: Box &#39;esxi55&#39; could not be found. Attempting to find and install...
 esx-01a: Box Provider: vmware_ovf, vcloud, vcenter
 esx-01a: Box Version: &gt;= 0
==&gt; esx-01a: Adding box &#39;esxi55&#39; (v0) for provider: vmware_ovf, vcloud, vcenter
 esx-01a: Downloading: file:///root/box-files/esxi55-vmware_ovf-1.1.box
==&gt; esx-01a: Successfully added box &#39;esxi55&#39; (v0) for &#39;vmware_ovf&#39;!
==&gt; esx-02a: Box &#39;esxi55&#39; could not be found. Attempting to find and install...
 esx-02a: Box Provider: vmware_ovf, vcloud, vcenter
 esx-02a: Box Version: &gt;= 0
==&gt; esx-02a: Adding box &#39;esxi55&#39; (v0) for provider: vmware_ovf, vcloud, vcenter
==&gt; esx-02a: Uploading [esxi55]...
==&gt; esx-02a: Adding [esxi55]
2015-01-03 16:28:34 -0600: networks: vlan2 = vlan2
2015-01-03 16:28:34 -0600: Uploading OVF to esx02.tyrell.corp...
==&gt; esx-01a: Uploading [esxi55]...
==&gt; esx-01a: Adding [esxi55]
2015-01-03 16:28:35 -0600: networks: vlan2 = vlan2
2015-01-03 16:28:35 -0600: Uploading OVF to esx01.tyrell.corp...
DEBUG: Timeout: 300
Iteration 1: Trying to get host&#39;s IP address ...
 % Total % Received % Xferd Average Speed Time Time Time Current
 Dload Upload Total Spent Left Speed
 15 473M 15 75.3M 0 0 4554k 0 0:01:46 0:00:16 0:01:30 4552k2015-01-03 16:29:02 -0600: Template already exists, waiting for it to be ready
 20 473M 20 98.8M 0 0 5122k 0 0:01:34 0:00:19 0:01:15 7489k2015-01-03 16:29:05 -0600: Template VM found
100 473M 100 473M 0 0 9245k 0 0:00:52 0:00:52 --:--:-- 9.9M
Iteration 1: Trying to access nfcLease.info.entity ...
HttpNfcLeaseComplete succeeded
esxi_box_url = &#39;/root/box-files/esxi55-vmware_ovf-1.1.box&#39;
==&gt; esx-02a: Creating VM...
2015-01-03 16:29:42 -0600: Template fully prepared and ready to be cloned
==&gt; esx-01a: Creating VM...
==&gt; esx-01a: Powering on VM...
==&gt; esx-02a: Powering on VM...</code></pre></figure>
 

<h4>B. Once the &quot;vagrant up&quot; command completes, you can check the status of the vms using &quot;vagrant status&quot;:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant esxi-test]# vagrant status
Current machine states:

esx-01a running (vcenter)
esx-02a running (vcenter)

This environment represents multiple VMs. The VMs are all listed
above with their current state. For more information about a specific
VM, run `vagrant status NAME`.</code></pre></figure>

<h4>C. Looking in vCenter you will see the virtual machines that vagrant deployed:</h4>

<p><img src="/assets/01-esx-01a.png" alt="screenshot"></p>

<h4>D. You can now ssh into either of the ESXi virtual machines using &quot;vagrant ssh [vm_name]&quot;:</h4>

<p>To connect to esx-01a you simply run &quot;vagrant ssh esx-01a&quot;:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant esxi-test]# vagrant ssh esx-01a
==&gt; esx-01a: External IP for esx-01a: 192.168.1.177
The time and date of this login have been sent to the system logs.

VMware offers supported, powerful system administration tools. Please
see www.vmware.com/go/sysadmintools for details.

The ESXi Shell can be disabled by an administrative user. See the
vSphere Security documentation for more information.

~ # esxcli network ip interface list
vmk0
 Name: vmk0
 MAC Address: 00:50:56:6f:9d:66
 Enabled: true
 Portset: vSwitch0
 Portgroup: Management Network
 Netstack Instance: defaultTcpipStack
 VDS Name: N/A
 VDS UUID: N/A
 VDS Port: N/A
 VDS Connection: -1
 MTU: 1500
 TSO MSS: 65535
 Port ID: 33554437
~ # exit
Connection to 192.168.1.177 closed.
[root@vagrant esxi-test]#</code></pre></figure>

<p>The same can be done for esx-02a:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant esxi-test]# vagrant ssh esx-02a
==&gt; esx-02a: External IP for esx-02a: 192.168.1.178
The time and date of this login have been sent to the system logs.

VMware offers supported, powerful system administration tools. Please
see www.vmware.com/go/sysadmintools for details.

The ESXi Shell can be disabled by an administrative user. See the
vSphere Security documentation for more information.
~ # esxcli network ip interface list
vmk0
 Name: vmk0
 MAC Address: 00:50:56:67:d5:b7
 Enabled: true
 Portset: vSwitch0
 Portgroup: Management Network
 Netstack Instance: defaultTcpipStack
 VDS Name: N/A
 VDS UUID: N/A
 VDS Port: N/A
 VDS Connection: -1
 MTU: 1500
 TSO MSS: 65535
 Port ID: 33554437
~ # exit
Connection to 192.168.1.178 closed.
[root@vagrant esxi-test]#</code></pre></figure>

<h4>E. Once we are done using our virtual machines they can be destroyed with a &quot;vagrant destroy&quot; command:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant esxi-test]# vagrant destroy
    esx-02a: Are you sure you want to destroy the &#39;esx-02a&#39; VM? [y/N] y
==&gt; esx-02a: Powering off VM...
==&gt; esx-02a: Destroying VM...
    esx-01a: Are you sure you want to destroy the &#39;esx-01a&#39; VM? [y/N] y
==&gt; esx-01a: Powering off VM...
==&gt; esx-01a: Destroying VM...
[root@vagrant esxi-test]#</code></pre></figure>

<h4>F. If you are ever unsure of the state of the vagrant virtual machines you can run &quot;vagrant status&quot; to check:</h4>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">[root@vagrant esxi-test]# vagrant status
Current machine states:

esx-01a                   not created (vcenter)
esx-02a                   not created (vcenter)

This environment represents multiple VMs. The VMs are all listed
above with their current state. For more information about a specific
VM, run `vagrant status NAME`.
[root@vagrant esxi-test]#</code></pre></figure>

<h3>That all for this post covering the basics of getting vagrant and the vagrant-vcenter provider installed/configured on CentOS.</h3>

<h3>Please provide any feedback or suggestions to my twitter account located on the about page.</h3>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page4">Older</a>
  
  
    
      <a class="pagination-item newer" href="/page2">Newer</a>
    
  
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

  </body>
</html>
